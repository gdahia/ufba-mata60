\documentclass[12pt]{article}

\usepackage{sbc-template}

\usepackage{graphicx,url}
\usepackage{amssymb}
\usepackage{amsmath}

\usepackage[brazil]{babel}   

\usepackage[utf8]{inputenc}
     
\sloppy

\title{Sugerindo colaborações na base de doutores da Plataforma Lattes usando Florestas Aleatórias}

\author{Gabriel Dahia, Gabriel L. P. e Souza, Pedro Vidal}

\address{Departamento de Ciência da Computação -- Universidade Federal da Bahia
  (UFBA)
  \email{\{gdahia,gabriellecomt,pvidal\}@dcc.ufba.br}
}

\begin{document} 

\maketitle

% TODO: abstract
% \begin{abstract}
%   This meta-paper describes the style to be used in articles and short papers
%   for SBC conferences. For papers in English, you should add just an abstract
%   while for the papers in Portuguese, we also ask for an abstract in
%   Portuguese (``resumo''). In both cases, abstracts should not have more than
%   10 lines and must be in the first page of the paper.
% \end{abstract}
     
% \begin{resumo} 
%   Este meta-artigo descreve o estilo a ser usado na confec��o de artigos e
%   resumos de artigos para publica��o nos anais das confer�ncias organizadas
%   pela SBC. � solicitada a escrita de resumo e abstract apenas para os artigos
%   escritos em portugu�s. Artigos em ingl�s dever�o apresentar apenas abstract.
%   Nos dois casos, o autor deve tomar cuidado para que o resumo (e o abstract)
%   n�o ultrapassem 10 linhas cada, sendo que ambos devem estar na primeira
%   p�gina do artigo.
% \end{resumo}


\section{Introdução}

A Plataforma Lattes, mantida pelo Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq), corresponde a integração de bases de dados de Currículos, de Grupos de Pesquisa e de Instituições, e pauta atividades de planejamento e gestão, e a formulação de políticas públicas dos órgaos governamentais brasileiros~\cite{lattes-cnpq}.
Em especial, o Currículo Lattes foi criado pelo CNPq para centralizar, padronizar e disponibilizar, através da Plataforma Lattes, informações pessoais, profissionais e acadêmicas da comunidade científica brasileira~\cite{sucupira}.
Essas informações são fornecidas pelos próprios autores dos currículos~\cite{sucupira} e oferecem grande abrangência e confiabilidade; o Lattes já é adotado pela maioria das instituições de fomento, universidades e instituições de pesquisa do Brasil~\cite{lattes-cnpq}.

Apesar da riqueza e potencial dessa base de dados, o CNPq impõe restrições ao acesso dessas informações, limitando o seu estudo~\cite{lattes-dataset}.
Com intuito de disseminar o conteúdo da Plataforma Lattes, foi publicado o conjunto de dados \emph{LattesDoctoralDataset}~\cite{lattes-dataset}.
Esta base contém dados a respeito do número e do tipo de publicações feitas, das colaborações entre pesquisadores, da atuação profissional e da formação acadêmica dos 265.187 doutores que possuem currículo publicado na plataforma, formatados em arquivos de formato \textit{comma separated values} (CSV).

Ao analisar as colaborações entre doutores nesse banco de dados, é possível perceber que seu número é de aproximadamente 0,02\% do total possível.
Assim, o foco desse trabalho é, analisando o \emph{LattesDoctoralDataset}, desenvolver um método de mineração de dados para sugerir ou prever novas colaborações com base nas informações fornecidas e nas colaborações preexistentes, com o intuito de fomentar colaborações entre pesquisadores e, por consequência, o avanço da ciência no Brasil.

Usando Florestas Aleatórias~\cite{random-forests}, o método proposto atinge acurácia de $86,70\%~\pm~0,18$, com 99\% de confiança, quando a tarefa é: dado um par de currículos, determinar se há pelo menos uma colaboração entre esses pesquisadores.
Quando a tarefa é estimar o número de colaborações entre um par de pesquisadores, dados os seus currículos, o método consegue acurácia de $78,34\%~\pm~0,16$, com 99\% de confiança.

O restante desse relatório é dividido da seguinte forma: a seção \ref{sec:methods} detalha a metodologia empregada, incluindo pré-processamento, divisão da base e experimentos, a seção \ref{sec:experiments} apresenta os experimentos, resultados e sua discussão, e a seção \ref{sec:conclusion} apresenta as conclusões do trabalho.

\section{Metodologia}
\label{sec:methods}

Para sugerir colaborações entre os doutores da base, primeiramente foi feito um pré-processamento na base de dados.
Este envolveu remover currículos com informações inconsistentes ou faltantes, agrupar as localizações e dados sobre a formação dos doutores, que são preenchidos livremente na Plataforma Lattes, utilizando técnicas de mineração de texto, e a remoção de atributos irrelevantes para a tarefa proposta.

% TODO: summarize random forests

\subsection{Pré-processamento}
\label{sec:preprocess}

A base de dados \emph{LattesDoctoralDataset} contém informação relativa a 265.187 currículos, identificados unicamente por um identificador inteiro no intervalo $\{1, 2, ..., 265.187\}$.
Seus dados estão divididos em seis arquivos de formato CSV, contendo informações sobre a atuação profissional de cada doutor, as colaborações relatadas entre doutores, informações dos doutores a partir da graduação até o pós-doutorado, sobre a produção científica de diversos tipos relatada por cada doutor, o nível de domínio em outras línguas dos doutores, e sobre as orientações realizadas ou andamento.
Para mais detalhes sobre a organização da base, sua coleta e conteúdo, o leitor interessado é referenciado ao artigo original de sua publicação~\cite{lattes-dataset}.

O primeiro passo do pré-processamento é o descarte de currículos que não tenham colaborações relatadas ou com informações faltantes.
Nessa etapa, todo currículo com valores inválidos nos campos de atuação profissional, e, excetuando o campo ``\texttt{pos-doutorado}'' e ``\texttt{especializacao}'', de formação acadêmica, são descartados.
Além disso, currículos que não tenham produção científica também são descartados, seguindo o entendimento que é um pré-requisito ao título de doutor possuir produção científica.
Campos cujos significados não estão claros na formatação da base, como a seção de proficiência em línguas e os últimos campos da formação acadêmica, também foram descartados.

Os campos que podem ser especificados livremente no Currículo Lattes apresentam enorme variabilidade na maneira de especificar a mesma informação.
Por exemplo, no campo referente ao local de graduação, usuários podem especificar ``USP'', ``Universidade de São Paulo'' e ``Univ. de SP'' para se referir a mesma instituição.

Em dois conjuntos de campos a variabilidade se sobressai.
O primeiro deles, a que denominou-se \texttt{lugares}, consiste de todos os campos prefixados por ``\texttt{local}'' e o campo ``\texttt{Instituicao Atual}''.
O segundo, chamado de \texttt{formacao}, contém ``\texttt{doutorado}'', ``\texttt{graduacao}'', ``\texttt{especializacao}'', ``\texttt{mestrado}'' e ``\texttt{pos-doutorado}''.

Para mitigar os efeitos dessa variabilidade, utilizou-se Análise Semântica Latente (abreviado em inglês como LSA)~\cite{lsa}.
Para isso, considerou-se cada entrada dos campos de ou \texttt{lugares}, ou \texttt{formacao}, a depender de qual conjunto está sendo agrupado, como um documento individual.
O resultado desse processo é que cada valor desses campos foi transformado em um vetor no espaço $\mathbb{R}^{100}$.
Em seguida, foi aplicado o algoritmo \emph{k-Means}~\cite{k-means} para agrupar o conjunto de valores dos campos em 500 grupos, no caso de \texttt{formacao}, ou 3.000 grupos, no caso de \texttt{lugares}.
No caso dos grupos de \texttt{lugares}, usamos um número de grupos superior ao número de instituições de ensino superior no Brasil, para abrigar outras instituições.
De acordo com os últimos dados coletados, este número é de 2.364 instituições~\cite{censo-mec}.

\begin{figure}
  \centering
  \includegraphics[width=0.5\textwidth]{graphs/mutual_information.pdf}
  \vspace{-15pt}
  \caption{Informação mútua de cada atributo com o atributo Colaborações para uma execução do método}
  \label{fig:mutual-info}
\end{figure}

Depois de agrupados os atributos acima, calculamos a produtividade de cada doutor como a soma das produtividades de cada uma das suas colaborações e adicionamos essa informação a base como o atributo ``\texttt{Colaboracoes}''.
Utilizando esse atributo como preditor da tarefa que se deseja resolver, calculamos, entre todo outro atributo $X$ da base de dados e $Y = \texttt{Colaboracoes}$ a informação mútua $I$:
\begin{equation}
  I(X, Y) = \sum_{y \in Y} \sum_{x \in X} p(x, y) \log \left( \frac{p(x, y)}{p(x)p(y)} \right),
\end{equation}
onde $p(x, y)$ é a probabilidade conjunta de $X$ e $Y$, e $p(x)$ e $p(y)$ são, respectivamente, as probabilidades marginais de $X$ e $Y$.
$p(x)$, $p(y)$ e $p(x, y)$ são estimados, respectivamente, como as frequências empíricas de $x$ em $X$, $y$ em $Y$, e $(x, y)$ em $(X, Y)$.

Informalmente, $I(X, Y)$ quantifica quão independente as variáveis $X$ e $Y$ são; isso permite quantificar dependências lineares, como a métrica correlação é capaz de fazer, e não-lineares entre as distribuições estudadas.

A figura~\ref{fig:mutual-info} mostra a informação mútua entre os atributos e ``\texttt{Colaboracoes}'' e os outros atributos considerados.
Nessa etapa, todos os atributos $X$ tais que $I(X, Y) = 0$, \emph{i.e.} os atributos $X$ e $Y$ são independentes, foram descartados do conjunto de dados.

O resultado da etapa de pré-processamento foi uma versão da base de dados em que, em uma determinada execução, restaram 8.180 currículos restritos aos atributos não independentes de ``\texttt{Colaboracoes}''.
Nesta versão da base, existem apenas 58.689 colaborações entre pesquisadores, em contraste com as 6.902.042 colaborações da base original.

% TODO: add figure illustrating the preprocessing pipeline

\subsection{Modelo de mineração de dados}
\label{sec:datamining}

Como os dados, tanto os atributos, quanto a saída, para o problema proposto são discretos, uma abordagem de mineração de dados adequada consiste na utilização de Florestas Aleatórias~\cite{random-forests}.

O método de Florestas Aleatórias pode ser descrito da seguinte maneira: são construídos $N$ conjuntos de dados de tamanho igual ao da base original, através do sorteio com repetição dos exemplos do conjunto de dados inicial.
Em cada uma dessas novas bases, é treinada uma Árvore de Decisão.
O conjunto de todas essas árvores é o modelo de mineração de dados.

Para fazer inferência com esse modelo, são computadas as classes previstas por cada uma das árvores da floresta.
A predição do modelo final é feita através do cálculo ou da média ou da moda das previsões individuais.

Esse modelo pode equivalentemente ser explicado como uso de \emph{bagging} para Árvores de Decisão.
Suas vantagens, conhecidas na literatura, são regularizar o modelo, diminuindo sobreajuste e aumentando a acurácia~\cite{random-forests}.

Nesse trabalho, utilizamos a implementação da biblioteca \emph{Scikit-learn}~\cite{sklearn} de Florestas Aleatórias, e limitamos o número de árvores à 10; os outros parâmetros são mantidos os padrões especificados pela biblioteca.

\section{Experimentos}
\label{sec:experiments}

Como há estocasticidade no método a partir da etapa de pré-processamento, rodamos nossos experimentos 10 vezes com sementes aleatórias diferentes.
Isso possibilita a obtenção de intervalos de confiança para nossos resultados.

Para cada execução individual do experimento, a base pré-processada foi dividida em um conjunto de treino, compreendendo 60\% do total de dados, e um conjunto de teste, com o restante.
A divisão é feita de maneira estratificada, considerando apenas se há ou não colaboração entre os donos dos currículos.

O restante do experimento consiste em treinar um modelo de Floresta Aleatória no conjunto de treino e validá-lo no conjunto de teste em duas modalidades distintas, que denominamos \texttt{binary} e \texttt{standard}.
A figura~\ref{fig:modalities} ilustra ambas modalidades.

\begin{figure}
  \begin{center}
    \includegraphics[width=0.45\textwidth]{images/binary.png}
    \hspace{10pt}
    \includegraphics[width=0.45\textwidth]{images/standard.png}
  \end{center}
  \caption{Modalidades de mineração de dados: à esquerda, a modalidade \texttt{binary}, em que é necessário apenas determinar se há ou não colaboração entre os donos dos currículos. À direita, a modalidade \texttt{standard}, onde o par de currículos é classificado de acordo com o número de colaborações previsto}
  \label{fig:modalities}
\end{figure}

Na modalidade \texttt{binary}, a tarefa consiste em determinar, dado um par de currículos de doutores, se há pelo menos uma colaboração entre eles.
Aqui, a Floresta Aleatória é treinada com pares de currículos como atributos e a informação de se há ou não colaboração entre eles como saída esperada.
Para fazer com que o modelo treinado seja invariante à ordem em que os currículos são colocados no par, duplicamos o conjunto de treino, colocando currículos nos dois sentidos.

Já na modalidade \texttt{standard}, a tarefa consiste em estimar, dado um par de currículos de doutores, o número de colaborações que existem entre eles.
Neste caso, o modelo é treinado com os pares de currículos e sua saída é uma classe de $\{0, 1, ..., M\}$, onde $M$ é o maior número de colaborações presente no conjunto de testes.

A validação do método usa a métrica acurácia, calculada como
\begin{equation}
  \textit{acurácia} = \frac{\text{Previsões corretas}}{\text{Total de previsões}}.
\end{equation}

Assim como é feito para o conjunto de treino, pares de currículos são também colocados nos dois sentidos.
Isso permite avaliar a robustez do método proposto à ordem em que os currículos são entregues ao modelo de mineração de dados sem artificialmente melhorar o resultado no conjunto de testes.

\subsection{Resultados}
\label{sec:results}
A partir das dez repetições do experimento, obteve-se $86,70\%~\pm~0,18$ de acurácia, com 99\% de confiança, para a modalidade \texttt{binary}, e $78,34\%~\pm~0,16$, com 99\% de confiança, para a modalidade \texttt{standard}.

Quando se compara estes resultados com a performance esperada de um classificador aleatório para essa mesma tarefa - dado que esta tarefa não foi tentada anteriormente e, portanto, não há estado-da-arte -, respectivamente 50\% para a modalidade \texttt{binary}, e 1,08\% (em média, existem 92 valores de colaborações possíveis) para a modalidade \texttt{standard}.

É importante notar que o resultado apresentado, na verdade, se trata de um limite inferior para a performance do modelo no conjunto de teste.
Isso ocorre porque, se para um determinado par de currículos para o qual foi previsto colaborações, não há colaboração relatada entre seus detentores, há três cenários possíveis: (1) realmente não há e nem nunca haverá colaboração entre esses pesquisadores e o modelo realmente fez uma classificação equivocada; (2) os doutores ainda não colaboraram, mas no futuro podem vir a colaborar; ou (3) há um erro no banco de dados e os doutores colaboraram, mas não relataram sua colaboração.
Nos cenários (2) e (3), a acurácia calculada do modelo é inferior ao valor correto.
Em especial, para o cenário (2), o \emph{LattesDoctoralDataset} não possui informação temporal e o modelo, portanto, não pode aprender esse tipo de informação.

Também é importante notar que a discrepância nos resultados entre as modalidades pode ser explicada pelo fato de a tarefa proposta para \texttt{standard} ser consideravelmente mais difícil do que a de \texttt{binary}: em um caso extremo, é possível que um dado número de colaborações não apareça no treino e todas as instãncias dessa classe seriam mal-classificadas.
Além do mais, a avaliação proposta não considera a proximidade do número de colaborações previsto do real; apenas previsões corretas são consideradas na métrica.

Apesar do grande número de nós em cada árvore (nos experimentos realizados, este número ficou na ordem de 10 mil), é possível realizar inferência no modelo, uma vez carregado em memória principal, em tempo real.
Isso ocorre porque a altura é, no máximo, o número de atributos fornecidos ao modelo, que não passa de 100. % em media, sao 96 atributos
Além disso, os arquivos dos modelos têm tamanho razoável: aqueles para a modalidade \texttt{binary} têm em torno de 15MB, e os \texttt{standard} têm em torno de 250MB.

% TODO: maybe daniela will complain about not comparing to similar works for other datasets, we can argue that in the specs, review is not listed. the limit of pages can also be listed as an argument. we can also use this excuse to say adjsutments to the text are required, prior to publication and stall it

\section{Conclusão}
\label{sec:conclusion}

% TODO: discuss limitations as future improvements

\bibliographystyle{sbc}
\bibliography{refs}

\end{document}
