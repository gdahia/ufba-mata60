\documentclass[12pt]{article}

\usepackage{sbc-template}

\usepackage{graphicx,url}
\usepackage{amssymb}
\usepackage{amsmath}

\usepackage[brazil]{babel}   

\usepackage[utf8]{inputenc}
     
\sloppy

\title{Sugerindo colaborações na base de doutores da Plataforma Lattes usando Florestas Aleatórias}

\author{Gabriel Dahia, Gabriel L. P. e Souza, Pedro Vidal}


\address{Departamento de Ciência da Computação -- Universidade Federal da Bahia
  (UFBA)
  \email{\{gdahia,gabriellecomt,pvidal\}@dcc.ufba.br}
}

\begin{document} 

\maketitle

% \begin{abstract}
%   This meta-paper describes the style to be used in articles and short papers
%   for SBC conferences. For papers in English, you should add just an abstract
%   while for the papers in Portuguese, we also ask for an abstract in
%   Portuguese (``resumo''). In both cases, abstracts should not have more than
%   10 lines and must be in the first page of the paper.
% \end{abstract}
     
% \begin{resumo} 
%   Este meta-artigo descreve o estilo a ser usado na confec��o de artigos e
%   resumos de artigos para publica��o nos anais das confer�ncias organizadas
%   pela SBC. � solicitada a escrita de resumo e abstract apenas para os artigos
%   escritos em portugu�s. Artigos em ingl�s dever�o apresentar apenas abstract.
%   Nos dois casos, o autor deve tomar cuidado para que o resumo (e o abstract)
%   n�o ultrapassem 10 linhas cada, sendo que ambos devem estar na primeira
%   p�gina do artigo.
% \end{resumo}


\section{Introdução}

A Plataforma Lattes, mantida pelo Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq), corresponde a integração de bases de dados de Currículos, de Grupos de Pesquisa e de Instituições, e pauta atividades de planejamento e gestão e a formulação de políticas públicas dos órgaos governamentais brasileiros~\cite{lattes-cnpq}.
Em especial, o Currículo Lattes foi criado pelo CNPq para centralizar, padronizar e disponibilizar, através da Plataforma Lattes, informações pessoais, profissionais e acadêmicas da comunidade científica brasileira~\cite{sucupira}.
Essas informações são fornecidas pelos próprios autores dos currículos~\cite{sucupira} e oferecem grande abrangência e confiabilidade; o Lattes já é adotado pela maioria das instituições de fomento, universidades e instituições de pesquisa do Brasil~\cite{lattes-cnpq}.

Apesar da riqueza e potencial dessa base de dados, o CNPq impõe restrições ao acesso dessas informações, limitando o seu estudo~\cite{lattes-dataset}.
Com intuito de disseminar o conteúdo da Plataforma Lattes, foi publicado o conjunto de dados \emph{LattesDoctoralDataset}~\cite{lattes-dataset}.
Esta base contém dados a respeito do número e do tipo de publicações feitas, das colaborações entre pesquisadores, da atuação profissional e da formação acadêmica dos 265.187 doutores que possuem currículo publicado na plataforma, formatados em arquivos de formato \textit{comma separated values} (CSV).

Ao analisar as colaborações entre doutores nesse banco de dados, é possível perceber que seu número é de aproximadamente 0,02\% do total possível.
Assim, o foco desse trabalho é, analisando o \emph{LattesDoctoralDataset}, desenvolver um método de mineração de dados para sugerir ou prever novas colaborações com base nas informações fornecidas e nas colaborações preexistentes, com o intuito de fomentar colaborações entre pesquisadores e, por consequência, o avanço da ciência no Brasil.

Usando Florestas Aleatórias~\cite{random-forests}, o método proposto atinge acurácia de $86,70\%~\pm~0,18$, com 99\% de confiança, quando a tarefa é: dado um par de currículos, determinar se há pelo menos uma colaboração entre esses pesquisadores.
Quando a tarefa é estimar o número de colaborações entre um par de pesquisadores, dados os seus currículos, o método consegue acurácia de $78,34\%~\pm~0,16$, com 99\% de confiança.

O restante desse relatório é dividido da seguinte forma: a seção \ref{sec:methods} detalha a metodologia empregada, incluindo pré-processamento, divisão da base e experimentos, a seção \ref{sec:experiments} apresenta os experimentos, resultados e sua discussão, e a seção \ref{sec:conclusion} apresenta as conclusões do trabalho.

\section{Metodologia}
\label{sec:methods}

Para sugerir colaborações entre os doutores da base, primeiramente foi feito um pré-processamento na base de dados.
Este envolveu remover currículos com informações inconsistentes ou faltantes, agrupar as localizações e dados sobre a formação dos doutores, que são preenchidos livremente na Plataforma Lattes, utilizando técnicas de mineração de texto, e a remoção de atributos irrelevantes para a tarefa proposta.

% TODO: summarize random forests

\subsection{Pré-processamento}
\label{sec:preprocess}

A base de dados \emph{LattesDoctoralDataset} contém informação relativa a 265.187 currículos, identificados unicamente por um identificador inteiro no intervalo $\{1, 2, ..., 265.187\}$.
Seus dados estão divididos em seis arquivos de formato CSV, contendo informações sobre a atuação profissional de cada doutor, as colaborações relatadas entre doutores, informações dos doutores a partir da graduação até o pós-doutorado, sobre a produção científica de diversos tipos relatada por cada doutor, o nível de domínio em outras línguas dos doutores, e sobre as orientações realizadas ou andamento.
Para mais detalhes sobre a organização da base, sua coleta e conteúdo, o leitor interessado é referenciado ao artigo original de sua publicação~\cite{lattes-dataset}.

O primeiro passo do pré-processamento é o descarte de currículos que não tenham colaborações relatadas ou com informações faltantes.
Nessa etapa, todo currículo com valores inválidos nos campos de atuação profissional, e, excetuando o campo ``\texttt{pos-doutorado}'' e ``\texttt{especializacao}'', de formação acadêmica, são descartados.
Além disso, currículos que não tenham produção científica também são descartados, seguindo o entendimento que é um pré-requisito ao título de doutor possuir produção científica.
Campos cujos significados não estão claros na formatação da base, como a seção de proficiência em línguas e os últimos campos da formação acadêmica, também foram descartados.

Os campos que podem ser especificados livremente no Currículo Lattes apresentam enorme variabilidade na maneira de especificar a mesma informação.
Por exemplo, no campo referente ao local de graduação, usuários podem especificar ``USP'', ``Universidade de São Paulo'' e ``Univ. de SP'' para se referir a mesma instituição.

Em dois conjuntos de campos a variabilidade se sobressai.
O primeiro deles, a que denominou-se \texttt{lugares}, consiste de todos os campos prefixados por ``\texttt{local}'' e o campo ``\texttt{Instituicao Atual}''.
O segundo, chamado de \texttt{formacao}, contém ``\texttt{doutorado}'', ``\texttt{graduacao}'', ``\texttt{especializacao}'', ``\texttt{mestrado}'' e ``\texttt{pos-doutorado}''.

Para mitigar os efeitos dessa variabilidade, utilizou-se Análise Semântica Latente (abreviado em inglês como LSA)~\cite{lsa}.
Para isso, considerou-se cada entrada dos campos de ou \texttt{lugares}, ou \texttt{formacao}, a depender de qual conjunto está sendo agrupado, como um documento individual.
O resultado desse processo é que cada valor desses campos foi transformado em um vetor no espaço $\mathbb{R}^{100}$.
Em seguida, foi aplicado o algoritmo \emph{k-Means}~\cite{k-means} para agrupar o conjunto de valores dos campos em 500 grupos, no caso de \texttt{formacao}, ou 3.000 grupos, no caso de \texttt{lugares}.
No caso dos grupos de \texttt{lugares}, usamos um número de grupos superior ao número de instituições de ensino superior no Brasil, para abrigar outras instituições.
De acordo com os últimos dados coletados, este número é de 2.364 instituições~\cite{censo-mec}.

\begin{figure}
  \centering
  \includegraphics[width=0.5\textwidth]{graphs/mutual_information.pdf}
  \vspace{-15pt}
  \caption{Informação mútua de cada atributo com o atributo Colaborações para uma execução do método}
  \label{fig:mutual-info}
\end{figure}

Depois de agrupados os atributos acima, calculamos a produtividade de cada doutor como a soma das produtividades de cada uma das suas colaborações e adicionamos essa informação a base como o atributo ``\texttt{Colaboracoes}''.
Utilizando esse atributo como preditor da tarefa que se deseja resolver, calculamos, entre todo outro atributo $X$ da base de dados e $Y = \texttt{Colaboracoes}$ a informação mútua $I$:
\begin{equation}
  I(X, Y) = \sum_{y \in Y} \sum_{x \in X} p(x, y) \log \left( \frac{p(x, y)}{p(x)p(y)} \right),
\end{equation}
onde $p(x, y)$ é a probabilidade conjunta de $X$ e $Y$, e $p(x)$ e $p(y)$ são, respectivamente, as probabilidades marginais de $X$ e $Y$.
$p(x)$, $p(y)$ e $p(x, y)$ são estimados, respectivamente, como as frequências empíricas de $x$ em $X$, $y$ em $Y$, e $(x, y)$ em $(X, Y)$.

Informalmente, $I(X, Y)$ quantifica quão independente as variáveis $X$ e $Y$ são; isso permite quantificar dependências lineares, como a métrica correlação é capaz de fazer, e não-lineares entre as distribuições estudadas.

A figura~\ref{fig:mutual-info} mostra a informação mútua entre os atributos e ``\texttt{Colaboracoes}'' e os outros atributos considerados.
Nessa etapa, todos os atributos $X$ tais que $I(X, Y) = 0$, \emph{i.e.} os atributos $X$ e $Y$ são independentes, foram descartados do conjunto de dados.

O resultado da etapa de pré-processamento foi uma versão da base de dados em que, em uma determinada execução, restaram 8.180 currículos restritos aos atributos não independentes de ``\texttt{Colaboracoes}''.
Nesta versão da base, existem apenas 58.689 colaborações entre pesquisadores, em contraste com as 6.902.042 colaborações da base original.

\subsection{Modelo de mineração de dados}
\label{sec:datamining}

Como os dados, tanto os atributos, quanto a saída, para o problema proposto são discretos, uma abordagem de mineração de dados adequada consiste na utilização de Florestas Aleatórias~\cite{random-forests}.

O método de Florestas Aleatórias pode ser descrito da seguinte maneira: são construídos $N$ conjuntos de dados de tamanho igual ao da base original, através do sorteio com repetição dos exemplos do conjunto de dados inicial.
Em cada uma dessas novas bases, é treinada uma Árvore de Decisão.
O conjunto de todas essas árvores é o modelo de mineração de dados.

Para fazer inferência com esse modelo, são computadas as classes previstas por cada uma das árvores da floresta.
A predição do modelo final é feita através ou do cálculo ou da média ou da moda das previsões individuais.

Esse modelo pode equivalentemente ser explicado como uso de \emph{bagging} para Árvores de Decisão.
Suas vantagens, conhecidas na literatura~\cite{random-forests}, são regularizar o modelo, diminuindo sobreajuste e aumentando a acurácia.

Nesse trabalho, utilizamos a implementação da biblioteca \emph{Scikit-learn}~\cite{sklearn} de Florestas Aleatórias, e limitamos o número de árvores à 10; os outros parâmetros são mantidos os padrões especificados pela biblioteca.

\section{Experimentos}
\label{sec:experiments}

Como há estocasticidade no método a partir da etapa pré-processamento, rodamos nossos experimentos 10 vezes com sementes aleatórias diferentes.
Isso possibilita a obtenção de intervalos de confiança para nossos resultados.

Para cada execução individual do experimento, a base pré-processada foi dividida em um conjunto de treino, compreendendo 60\% do total de dados, e um conjunto de teste, com o restante.
A divisão é feita de maneira estratificada, considerando apenas se há ou não colaboração entre os donos dos currículos.

O restante do experimento consiste em treinar um modelo de Floresta Aleatória no conjunto de treino e validá-lo no conjunto de teste em duas modalidades distintas, que denominamos \texttt{binary} e \texttt{standard}.

Na modalidade \texttt{binary}, a tarefa consiste em determinar, dado um par de currículos de doutores, se há pelo menos uma colaboração entre eles.
Aqui, a Floresta Aleatória é treinada com pares de currículos como atributos e a informação de se há ou não colaboração entre eles como saída esperada.
Para fazer com que o modelo treinado seja invariante à ordem em que os currículos são colocados no par, duplicamos o conjunto de treino, colocando currículos nos dois sentidos.

Já na modalidade \texttt{standard}, a tarefa consiste em determinar, dado um par de currículos de doutores, estimar o número de colaborações que existem entre eles.
Neste caso, o modelo é treinado com os pares de currículos e sua saída é uma classe de $\{0, 1, ..., M\}$, onde $M$ é o maior número de colaborações presente no conjunto de testes.

A validação do método usa a métrica acurácia, calculada como
\begin{equation}
  \textit{acurácia} = \frac{\text{Previsões corretas}}{\text{Total de previsões}}.
\end{equation}

% TODO: add figures illustrating both standard and binary tasks pipelines, including the preprocessing of the CVs

\subsection{Resultados}
\label{sec:results}
Realizando dez repetições do nosso experimento, obtivemos $86,70\%~\pm~0,18$ de acurácia, com 99\% de confiança, para a modalidade \texttt{binary}, e $78,34\%~\pm~0,16$, com 99\% de confiança, para a modalidade \texttt{standard}.

% TODO: state that we also duplicate the test set to assess symmetry invariance and show that this does not make the task easier

% TODO: put number of nodes in both cases

\section{Conclusão}
\label{sec:conclusion}

\bibliographystyle{sbc}
\bibliography{refs}

\end{document}
